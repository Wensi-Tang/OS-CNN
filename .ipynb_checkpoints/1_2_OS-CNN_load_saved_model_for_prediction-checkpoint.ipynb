{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset: FiftyWords\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import dirname\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from utils.dataloader.TSC_data_loader import TSC_data_loader\n",
    "from Classifiers.OS_CNN.OS_CNN_Structure_build import generate_layer_parameter_list\n",
    "from Classifiers.OS_CNN.log_manager import eval_condition, eval_model, save_to_log\n",
    "from Classifiers.OS_CNN.OS_CNN import OS_CNN\n",
    "\n",
    "\n",
    "# model saved in result log folder\n",
    "Result_log_folder = './Results_of_OS_CNN/OS_CNN_result_iter_0/'\n",
    "dataset_path = dirname(\"./Example_Datasets/UCRArchive_2018/\")\n",
    "dataset_name = 'FiftyWords'\n",
    "\n",
    "#batch_size for test\n",
    "batch_size = 16\n",
    "print('test dataset:', dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code is running on:  cuda:0\n",
      "the size of inpute dataset is: 270\n",
      "number of class is: tensor(50, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_train, y_train, X_test, y_test = TSC_data_loader(dataset_path, dataset_name)    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('code is running on: ',device)    \n",
    "    \n",
    "# put data to GPU\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_train.requires_grad = False\n",
    "X_train = X_train.to(device)\n",
    "X_train = X_train.unsqueeze_(1)\n",
    "y_train = torch.from_numpy(y_train).to(device)\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test.requires_grad = False\n",
    "X_test = X_test.to(device)\n",
    "X_test = X_test.unsqueeze_(1)\n",
    "y_test = torch.from_numpy(y_test).to(device)\n",
    "input_shape = X_train.shape[-1]\n",
    "n_class = max(y_train) + 1\n",
    "print('the size of inpute dataset is:',input_shape)\n",
    "print('number of class is:',n_class)\n",
    "    \n",
    "    \n",
    "#build dataloader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=int(min(X_train.shape[0] / 10, batch_size)), shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(min(X_train.shape[0] / 10, batch_size)), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of inpute data is: torch.Size([450, 1, 270])\n",
      "the max size of kernel is: 67\n",
      "the Network structure for FiftyWords is:\n",
      "[[(1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 1, 5), (1, 1, 7), (1, 1, 11), (1, 1, 13), (1, 1, 17), (1, 1, 19), (1, 1, 23), (1, 1, 29), (1, 1, 31), (1, 1, 37), (1, 1, 41), (1, 1, 43), (1, 1, 47), (1, 1, 53), (1, 1, 59), (1, 1, 61), (1, 1, 67)], [(20, 20, 1), (20, 20, 2), (20, 20, 3), (20, 20, 5), (20, 20, 7), (20, 20, 11), (20, 20, 13), (20, 20, 17), (20, 20, 19), (20, 20, 23), (20, 20, 29), (20, 20, 31), (20, 20, 37), (20, 20, 41), (20, 20, 43), (20, 20, 47), (20, 20, 53), (20, 20, 59), (20, 20, 61), (20, 20, 67)], [(400, 20, 1), (400, 20, 2)]]\n"
     ]
    }
   ],
   "source": [
    "#net parameter\n",
    "paramenter_number_of_layer_list = [8*128, 5*128*256 + 2*256*128] \n",
    "Max_kernel_size = 89\n",
    "\n",
    "# calcualte network structure\n",
    "receptive_field_shape= min(int(X_train.shape[-1]/4),Max_kernel_size)\n",
    "print('the shape of inpute data is:',X_train.shape)\n",
    "print('the max size of kernel is:', receptive_field_shape)\n",
    "layer_parameter_list = generate_layer_parameter_list(1,receptive_field_shape,paramenter_number_of_layer_list)\n",
    "print('the Network structure for',dataset_name,'is:')\n",
    "print(layer_parameter_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiftyWords test acc =  0.8153846153846154\n"
     ]
    }
   ],
   "source": [
    "# find model path\n",
    "best_model_path = Result_log_folder +dataset_name+'/'+dataset_name+'Best_model'\n",
    "\n",
    "# build os-cnn net and load weight\n",
    "torch_FCN = OS_CNN(layer_parameter_list, n_class.item(), False).to(device)\n",
    "torch_FCN.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "torch_FCN.eval()\n",
    "\n",
    "acc_test = eval_model(torch_FCN, test_loader)\n",
    " \n",
    "sentence = str(acc_test)\n",
    "torch.cuda.empty_cache()\n",
    "print(dataset_name,'test acc = ', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
